
.. blogpost::
    :title: Réseaux de neurones et arbres de décision
    :keywords: inégalités
    :date: 2020-08-22
    :categories: machine learning

    Je ne peux m'empêcher parfois de m'embarquer dans
    l'implémentation d'une idée que j'ai eue, simplement
    parce que je pense que c'est possible, que je la voie
    devant moi sans pouvoir la toucher. J'ai imaginé
    une façon de convertir un arbre de décision en un arbre
    de décision, parce qu'une fonction sigmoïde est une
    approximation d'une fonction en escalier. Je me suis
    toujours que c'était possible sans vraiment aller jusqu'au
    bout car je n'avais aucun doute là-dessus. Et puis
    j'ai commencé à faire un lien entre ce mécanisme et la
    possibilité de créer une arbre de décision où chaque noeud
    n'est plus un seuil sur une variable mais sur une droite :
    :ref:`l-decnntrees`. Cela permettrait de construire des arbres
    avec n'importe quelle séparation linéaire au lieu de seulement
    des horizontales et des verticales, donc tout autant
    interprétable et probablement plus petit.

    J'ai pensé à plusieurs façons de constuire de tels arbres.
    L'une d'elles est la conversion d'un arbre de décision
    en un réseau de neurones puis de s'en servir comme
    initialisation lors de l'apprentissage des coefficients.
    La suite est lisible dans le notebook :ref:`neuraltreerst`.

    Ca doit être la cinquième fois que j'implémente des réseaux
    de neurones. La première... c'était il y a plus de 20 ans.
    On peut faire des choses très jolies en terme de design
    mais le plus efficace est souvent de générer du code C++ pour
    une architecture précise et de recompiler le tout,
    ce que je n'ai pas fait cette fois-ci ce que fait *tensorflow*.
